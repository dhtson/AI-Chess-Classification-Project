{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix using seaborn heatmap.\n",
    "    \n",
    "    Args:\n",
    "    cm (array): Confusion matrix.\n",
    "    class_names (list): List of class names for labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))  # Set plot size\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(data_path, epochs=100, batch_size=64, learning_rate=0.001, model_save_path=\"chess_model.pth\", patience=15):\n",
    "    \"\"\"\n",
    "    Trains a ResNet18 model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "    data_path (str): Path to the dataset directory.\n",
    "    epochs (int): Number of training epochs.\n",
    "    batch_size (int): Size of each training batch.\n",
    "    learning_rate (float): Learning rate for the optimizer.\n",
    "    model_save_path (str): Path to save the best model.\n",
    "    patience (int): Number of epochs to wait for improvement before early stopping.\n",
    "    \"\"\"\n",
    "    # Check if GPU is available, else use CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Define data transformations for preprocessing and augmentation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224 (input size for ResNet18)\n",
    "        transforms.RandomRotation(15),  # Randomly rotate images by up to 15 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust color properties\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values\n",
    "    ])\n",
    "\n",
    "    # Load dataset from the specified directory\n",
    "    dataset = datasets.ImageFolder(os.path.join(data_path, \"train\"), transform=transform)\n",
    "    num_classes = len(dataset.classes)  # Get the number of classes\n",
    "\n",
    "    # Print class names and their indices\n",
    "    print(f\"Classes: {dataset.classes}\")\n",
    "    print(f\"Class-to-Index Mapping: {dataset.class_to_idx}\")\n",
    "\n",
    "    # Split dataset into training and validation sets (80-20 split)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoader objects for batch loading\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load the pre-trained ResNet18 model\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    # Replace the final fully connected layer to match the number of classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)  # Move model to the appropriate device (GPU/CPU)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Learning rate scheduler to reduce learning rate when validation loss plateaus\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "    # Variables to track the best validation loss and early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Lists to store accuracies for plotting\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training step\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)  # Get predicted labels\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        # Compute training accuracy\n",
    "        train_acc = correct_train / total_train\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Validation step\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "                # Collect predictions and true labels for evaluation\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Compute validation loss and accuracy\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = correct_val / total_val\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Print metrics for the current epoch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_acc * 100:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc * 100:.2f}%\")\n",
    "\n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "        # Save the model if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), model_save_path)  # Save model\n",
    "            print(f\"Model saved to {model_save_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement for {patience_counter} epoch(s).\")\n",
    "\n",
    "        # Stop training if validation loss does not improve for 'patience' epochs\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Compute and display confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    plot_confusion_matrix(cm, dataset.classes)\n",
    "\n",
    "    # Display classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
    "\n",
    "    # Plot training and validation accuracies over epochs\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Val Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script to initiate the training process\n",
    "if __name__ == \"__main__\":\n",
    "    # Download dataset using kagglehub and train the model\n",
    "    path = kagglehub.dataset_download('koinguyn/chess-detection')\n",
    "    data_path = f\"{path}\"\n",
    "    train_model(data_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
